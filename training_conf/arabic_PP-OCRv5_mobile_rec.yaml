Global:
  model_name: arabic_PP-OCRv5_mobile_rec
  debug: true
  use_gpu: true
  epoch_num: 75 # Fine-tuning usually needs fewer epochs, but 75 is safe.
  log_smooth_window: 20
  print_batch_step: 20 #changed from 10 (Optional). Since the batch size is smaller, the total number of "steps" per epoch will double. If this is set to 10, your logs will scroll very fast. You might want to double this value (e.g., to 20) to keep your logs cleaner.
  save_model_dir: ./output/arabic_rec_ppocr_v5
  save_epoch_step: 10
  eval_batch_step: [0, 500] # ### Check eval more frequently (was 1000)
  cal_metric_during_train: true
  
  # ### POINT THIS TO YOUR PRETRAINED MODEL PATH ###
  pretrained_model: /home/sara/data/capmas/vsworkspace/capmas_projects/paddle_models/original/arabic_PP-OCRv5_mobile_rec/arabic_PP-OCRv5_mobile_rec_pretrained
  
  checkpoints:
  save_inference_dir:
  use_visualdl: true # ### Changed to True (useful for monitoring loss curves)
  infer_img:
  character_dict_path: ./ppocr/utils/dict/ppocrv5_arabic_dict.txt
  
  # ### CRITICAL: Increased to support "Large document lines"
  # Was 25. If a line has 80 chars, 25 cuts it off. 
  # 100 is usually enough for a full line of A4 text.
  max_text_length: &max_text_length 25 
  
  infer_mode: false
  use_space_char: true
  distributed: false # ### Set false for single GPU training
  save_res_path: ./output/rec/predicts_arabic_ppocrv5.txt
  
  # d2s_train_image_shape: [3, 48, 320]
  # Change 320 to 640 or 800 to initialize the model for wider text
  # NEW (Matches your largest scale)
  d2s_train_image_shape: [3, 48, 320]

  # ### MEMORY OPTIMIZATION (AMP) ###
  # Essential for 8GB GPU to run reasonably sized batches
  use_amp: true
  scale_loss: 1024.0
  use_dynamic_loss_scaling: true

Optimizer:
  name: Adam
  beta1: 0.9
  beta2: 0.999
  lr:
    name: Cosine
    # ### LOWERED LR FOR FINE-TUNING ###
    # 0.0005 is too high for pre-trained weights. 
    # 0.0001 is safer to prevent destroying learned features.
    learning_rate: 0.00025 #0.0001 
    warmup_epoch: 2 # Reduced warmup since we are fine-tuning
  regularizer:
    name: L2
    factor: 3.0e-05

Architecture:
  model_type: rec
  algorithm: SVTR_LCNet
  Transform:
  Backbone:
    name: PPLCNetV3
    scale: 0.95
  Head:
    name: MultiHead
    head_list:
      - CTCHead:
          Neck:
            name: svtr
            dims: 120
            depth: 2
            hidden_dims: 120
            kernel_size: [1, 3]
            use_guide: True
          Head:
            fc_decay: 0.00001
      - NRTRHead:
          nrtr_dim: 384
          max_text_length: *max_text_length # Inherits 100 from Global

Loss:
  name: MultiLoss
  loss_config_list:
    - CTCLoss:
    - NRTRLoss:

PostProcess:  
  name: CTCLabelDecode

Metric:
  name: RecMetric
  main_indicator: acc
  ignore_space: False

Train:
  dataset:
    name: MultiScaleDataSet
    ds_width: false
    data_dir: ./train_data/
    ext_op_transform_idx: 1
    label_file_list:
    - /home/sara/data/capmas/vsworkspace/capmas_projects/train_data/rec/train.txt
    transforms:
    - DecodeImage:
        img_mode: BGR
        channel_first: false
    # ### COMMENTED OUT RecConAug FOR MEMORY ###
    # Reconstruction Augmentation consumes extra memory and 
    # can conflict with dynamic widths on small GPUs.
    # - RecConAug:
    #     prob: 0.5
    #     ext_data_num: 2
    #     image_shape: [48, 320, 3]
    #     max_text_length: *max_text_length
    - RecAug:
    - MultiLabelEncode:
        gtc_encode: NRTRLabelEncode
    - KeepKeys:
        keep_keys:
        - image
        - label_ctc
        - label_gtc
        - length
        - valid_ratio
  sampler:
    name: MultiScaleSampler
    # ### THE MIXED TEXT SOLUTION ###
    # Instead of varying height (original), we vary WIDTH.
    # 320: Perfect for "Small table cells" (no stretching)
    # 480: Medium text
    # 640: Perfect for "Large document lines" (no squashing)

    # scales: [[320, 48], [480, 48], [640, 48]]

    # ### THE HYBRID SOLUTION ###
    # [320, 48]: For single words / short IDs (Fastest)
    # [640, 48]: For medium phrases
    # [960, 48]: For longer sentences
    # [1280, 48]: For your max length 100-char lines
    # scales: [[320, 48], [640, 48], [960, 48], [1280, 48]]


    scales: [[320, 32], [320, 48], [320, 64]]
    
    # ### BATCH SIZE FOR 8GB GPU ###
    # 128 is too big for 8GB VRAM with AMP enabled. 
    # 32 or 48 is safe. Start with 32.

    first_bs: &bs 64 #32 
    fix_bs: false
    divided_factor: [8, 16] 
    is_training: True
  loader:
    shuffle: true
    batch_size_per_card: *bs
    drop_last: true
    num_workers: 8

Eval:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data/
    label_file_list:
    - /home/sara/data/capmas/vsworkspace/capmas_projects/train_data/rec/val.txt
    transforms:
    - DecodeImage:
        img_mode: BGR
        channel_first: false
    - MultiLabelEncode:
        gtc_encode: NRTRLabelEncode
    - RecResizeImg:
        # ### VALIDATION RESIZE ###
        # We must use the largest size (640) for validation
        # so your long document lines don't get crushed.
        # Short text might look padded, but that's acceptable for Eval.
        # image_shape: [3, 48, 640]  #480 or 640???

        # Increase this to match your largest training scale
        # WAS: [3, 48, 960]
        # CHANGE TO: Match the largest scale in Train -> sampler
        image_shape: [3, 48, 320]
    - KeepKeys:
        keep_keys:
        - image
        - label_ctc
        - label_gtc
        - length
        - valid_ratio
  loader:
    shuffle: true
    drop_last: false
    batch_size_per_card: 64 # Reduced for 8GB GPU
    num_workers: 4